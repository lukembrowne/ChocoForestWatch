name: Deploy (build on droplet)

on:
  push:
    branches: [main]          # production branch
  workflow_dispatch:          # allows manual triggering

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      - name: SSH into droplet, pull latest code, rebuild & restart
        uses: appleboy/ssh-action@v1.0.3
        with:
          host:    ${{ secrets.DO_HOST }}
          username: root
          key:     ${{ secrets.DO_SSH_KEY }}
          script: |
            set -euo pipefail

            # 1. Make sure the repo is present
            cd /root/opt || mkdir -p /root/opt && cd /root/opt
            if [ -d ChocoForestWatch/.git ]; then
              echo "Repo exists – pulling latest commit"
              cd ChocoForestWatch
              git pull --ff-only
            else
              echo "Cloning repo for the first time"
              git clone --depth 1 git@github.com:lukembrowne/ChocoForestWatch.git
              cd ChocoForestWatch
            fi

            # 2. Load environment file (already on server) – optional sanity check
            test -f .env || { echo ".env missing!"; exit 1; }

            # 3. Source .env to load environment variables into this script
            set -a
            source .env
            set +a

            # 4. Build the images locally on the droplet
            # Always use production settings when deploying
            
            docker compose -f docker-compose.prod.yml down

            docker compose -f docker-compose.prod.yml build \
              --build-arg VITE_API_URL="${VITE_API_URL}" \
              --build-arg VITE_SENTRY_DSN="${VITE_SENTRY_DSN}" \
              --build-arg DJANGO_DEBUG="${DJANGO_DEBUG}" \
              --build-arg AWS_ACCESS_KEY_ID="${AWS_ACCESS_KEY_ID}" \
              --build-arg AWS_SECRET_ACCESS_KEY="${AWS_SECRET_ACCESS_KEY}" \
              --build-arg AWS_S3_ENDPOINT="${AWS_S3_ENDPOINT}" \
              --build-arg AWS_REGION="${AWS_REGION}" \
              --build-arg VITE_TITILER_URL="${VITE_TITILER_URL}" \
              --build-arg TITILER_URL="${TITILER_URL}" \
              --build-arg POSTGRES_USER="${POSTGRES_USER}" \
              --build-arg POSTGRES_PASSWORD="${POSTGRES_PASSWORD}" \
              --build-arg POSTGRES_DB="${POSTGRES_DB}" \
              --build-arg POSTGRES_HOST="${POSTGRES_HOST}" \
              --build-arg POSTGRES_PORT="${POSTGRES_PORT}" \
              --build-arg POSTGRES_PASSWORD="${POSTGRES_PASSWORD}" \
              --build-arg DB_HOST="${DB_HOST}" \
              --build-arg DB_PORT="${DB_PORT}" \
              --build-arg DB_IP="${DB_IP}" \
              --build-arg POSTGRES_PASS="${POSTGRES_PASS}" \
              --build-arg POSTGRES_DBNAME="${POSTGRES_DBNAME}" \
              --build-arg POSTGRES_HOST="${POSTGRES_HOST}" \
              --build-arg POSTGRES_PORT="${POSTGRES_PORT}" \
              --build-arg BOUNDARY_GEOJSON_PATH="${BOUNDARY_GEOJSON_PATH}" \
              --build-arg DEFAULT_PUBLIC_PROJECT_ID="${DEFAULT_PUBLIC_PROJECT_ID}" \
              --build-arg VITE_DEFAULT_PUBLIC_PROJECT_ID="${VITE_DEFAULT_PUBLIC_PROJECT_ID}" \
              --build-arg UMAMI_APP_SECRET="${UMAMI_APP_SECRET}" \
              --build-arg VITE_UMAMI_WEBSITE_ID="${VITE_UMAMI_WEBSITE_ID}" \
              --build-arg VITE_UMAMI_URL="${VITE_UMAMI_URL}" \
              --build-arg UMAMI_DB_NAME="${UMAMI_DB_NAME}" \
              --build-arg UMAMI_DB_USER="${UMAMI_DB_USER}" \
              --build-arg UMAMI_DB_PASSWORD="${UMAMI_DB_PASSWORD}"
            
            docker compose -f docker-compose.prod.yml up -d --build

            # 5. Optional: prune dangling images to save disk
            docker image prune -f

            #6. Calculate forest cover stats for western Ecuador in cache
            docker compose exec backend python manage.py precalculate_western_ecuador_stats --db-host remote